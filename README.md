# Sistema de Resiliencia Operativa y DRP (Plan de Recuperaci√≥n ante Desastres)

----
## Descripci√≥n del Proyecto

### El Problema: 
En la administraci√≥n de sistemas tradicional, los backups suelen fallar silenciosamente. Los scripts de copia (`cp`, `rsync`) no garantizan la consistencia si la base de datos est√° escribiendo en ese momento, y la recuperaci√≥n manual ("DRP en papel") es lenta y propensa a errores humanos bajo presi√≥n.

> **Si un backup no ha sido probado mediante una restauraci√≥n, no existe.**

### La Soluci√≥n
Este proyecto implementa un **Sistema de Resiliencia Automatizada** dise√±ado para cumplir con los est√°ndares de **Continuidad Operacional**. Transformamos el DRP en c√≥digo ejecutable para garantizar que la recuperaci√≥n sea:
1.  **Consistente:** Uso de **LVM Snapshots** para "congelar" el estado del disco en milisegundos, asegurando que la base de datos (MariaDB) nunca se copie en un estado corrupto.
2.  **Eficiente:** Implementaci√≥n de **Restic** para backups incrementales con deduplicaci√≥n. Solo se transmiten y almacenan los bytes que han cambiado, reduciendo el uso de red y almacenamiento.
3.  **Gestionada:** Aplicaci√≥n de pol√≠ticas de retenci√≥n **GFS (Grandfather-Father-Son)** autom√°ticas para mantener copias hist√≥ricas sin saturar el almacenamiento.
4.  **Inmortal:** Orquestaci√≥n con **Ansible** para automatizar la resurrecci√≥n completa del servicio en minutos, eliminando el factor humano durante la crisis.

---

## üèóÔ∏è Arquitectura de la Soluci√≥n

El sistema se distribuye en **4 Nodos L√≥gicos** interconectados, dise√±ados para simular un entorno de producci√≥n real donde los servicios (App/DB), el almacenamiento (Backups) y la gesti√≥n (Control) est√°n desacoplados para garantizar la supervivencia de los datos incluso si los servidores principales son comprometidos.



[Image of network star topology]


| Nodo | Rol | Funci√≥n Cr√≠tica |
| :--- | :--- | :--- |
| **VM1** | `B√≥veda (Storage)` | Almacenamiento inmutable de backups (MinIO). Act√∫a como "caja negra" externa. |
| **VM2** | `App Node` | Servidor Web (Nginx/Apache). Representa la cara visible del negocio. |
| **VM3** | `DB Node` | Base de Datos (MariaDB) sobre l√∫menes LVM. Es el activo m√°s valioso. |
| **VM4** | `Cerebro (Control)` | Nodo de gesti√≥n desde donde Ansible ejecuta la recuperaci√≥n autom√°tica. |

---

## Tecnolog√≠as Seleccionadas

### 1. Motor de Backup: Restic

* **¬øPor qu√©?** **Restic** utiliza una arquitectura de **"Chunk-Based Deduplication"** (Deduplicaci√≥n basada en fragmentos).
* **Eficiencia:** Si cambias 1 MB en una base de datos de 10 GB, Restic solo transfiere y guarda ese 1 MB. Esto cumple con el requisito de **estrategia incremental** sin la complejidad de gestionar cadenas de incrementales fr√°giles.
* **Seguridad:** Todo dato que sale del servidor es cifrado con **AES-256** (Cifrado sim√©trico fuerte con una longitud clave de 256 bits) antes de tocar la red.

### 2. Consistencia de Datos: LVM (Logical Volume Manager)
> *Requisito: Integridad en Caliente*

* **El Desaf√≠o:** Copiar los archivos de una base de datos mientras est√° encendida resulta en backups corruptos e inutilizables.
* **La Soluci√≥n:** Utilizamos **Snapshots LVM**. Esto "congela" el sistema de archivos en el tiempo exacto en milisegundos, permitiendo a Restic copiar los datos est√°ticos mientras la base de datos sigue recibiendo escrituras en un espacio temporal.

### 3. Planificaci√≥n: Systemd Timers

* **La Mejora:** **Systemd** maneja dependencias (ej: *"no inicies el backup si no hay red"*), reintentos autom√°ticos si falla la conexi√≥n, y registro de logs centralizado (`journalctl`). Es vital para la **Automatizaci√≥n** robusta.

### 4. Orquestaci√≥n DRP: Ansible
> *Requisito: Automatizaci√≥n de la Restauraci√≥n*

* **¬øPor qu√©?** Un Plan de Recuperaci√≥n ante Desastres (DRP) documentado en papel es lento y propenso a error humano durante una crisis.
* **La Soluci√≥n:** Transformamos el DRP en **Playbooks de Ansible**. Esto nos permite reconstruir el servicio, reinstalar dependencias y restaurar los datos con un solo comando, reduciendo el **RTO (Recovery Time Objective)** de horas a minutos.

---
## üìÖ Estrategia de Retenci√≥n de Datos

### Perfil Producci√≥n (GFS en un entorno serio)
En un entorno empresarial real, aplicamos el esquema est√°ndar **Grandfather-Father-Son** para cumplir con auditor√≠as y recuperaci√≥n a largo plazo:

* **Son (Diario):** `--keep-daily 7` (Mantiene 1 backup por d√≠a durante una semana).
* **Father (Semanal):** `--keep-weekly 4` (Mantiene 1 por semana durante un mes).
* **Grandfather (Mensual):** `--keep-monthly 6` (Mantiene 1 por mes durante medio a√±o).

### Perfil Demostraci√≥n (Para la demostracion para la feria)
> Debido a la naturaleza ef√≠mera del evento (ciclos de vida de minutos), hemos ajustado el "cron√≥metro" para operar en **Alta Frecuencia**:

* **Frecuencia de Backup:** Cada **60 segundos** (Systemd Timer).
* **Pol√≠tica de Retenci√≥n:** `keep-last 20`.
    * *Justificaci√≥n:* Esto nos permite viajar en el tiempo minuto a minuto durante la presentaci√≥n, mostrando cambios inmediatos sin esperar d√≠as o semanas.



> *Esto demuestra la capacidad de Restic para gestionar el ciclo de vida de los datos sin intervenci√≥n humana, escalando desde minutos (demo) hasta a√±os (producci√≥n).*

---

##  Protocolo de Integridad 
Un riesgo cr√≠tico en sistemas automatizados es que el backup autom√°tico se ejecute *justo despu√©s* de un incidente destructivo, guardando un estado "vac√≠o" o corrupto como el m√°s reciente (`latest`).

**Nuestra Soluci√≥n: Restauraci√≥n por ID Inmutable.**
En lugar de restaurar ciegamente la etiqueta `latest`, nuestro **Men√∫ de Control (Ansible)** permite al operador seleccionar un **Snapshot ID** espec√≠fico.
1.  El sistema sigue haciendo backups (incluso del desastre), lo cual sirve como registro forense.
2.  El operador visualiza la l√≠nea de tiempo.
3.  Se selecciona el punto de restauraci√≥n *previo* al incidente (T-1 minuto).

> **Resiliencia no es solo guardar datos, es saber qu√© versi√≥n de la verdad recuperar.**

***

# Fases de Implementaci√≥n

Para garantizar la replicabilidad y el √©xito del **Sistema de Resiliencia Operativa**, hemos dividido la ejecuci√≥n en 9 fases estrat√©gicas. Cada fase construye una capa de funcionalidad sobre la anterior, desde la infraestructura f√≠sica hasta la interfaz de usuario final.

-----

## üìç Fase 1: Aprovisionamiento de Infraestructura Base
**Descripci√≥n:**
Consiste en la creaci√≥n y configuraci√≥n inicial de los 4 Nodos Virtuales (VMs) que compondr√°n el sistema. Se establecen los recursos de hardware virtual (CPU, RAM, Disco) y se instala el sistema operativo base (Ubuntu Server).

**Objetivo y Aporte:**
* Establecer los cimientos del sistema.
* Segregar funciones: Separar la l√≥gica de negocio (App/DB), el almacenamiento (B√≥veda) y la gesti√≥n (Control) para evitar un "Punto √önico de Fallo" (SPOF).

-----

## üìç Fase 2: Implementaci√≥n de Red de Malla (Overlay Network)
**Descripci√≥n:**
Despliegue de una red privada virtual (VPN de malla) utilizando **Tailscale/ZeroTier**. Esto crea una capa de red abstracta sobre la infraestructura f√≠sica, permitiendo que las m√°quinas se comuniquen de forma segura y encriptada sin depender de la configuraci√≥n del router local (Wi-Fi de la feria o laboratorio).

**Objetivo y Aporte:**
* **Portabilidad Total:** El sistema funciona id√©nticamente en el laboratorio, en una feria p√∫blica o en Internet.
* **Independencia de IP:** Uso de *MagicDNS* para resolver nombres (`db-node`, `app-node`) en lugar de depender de IPs est√°ticas fr√°giles.
* **Seguridad:** Todo el tr√°fico entre nodos viaja cifrado, inmune a espionaje en redes p√∫blicas.

-----

## üìç Fase 3: Despliegue de la B√≥veda Inmutable (Object Storage)
**Descripci√≥n:**
Instalaci√≥n y configuraci√≥n de **MinIO** (compatible con Amazon S3) en un entorno contenerizado (Docker). Se configuran las pol√≠ticas de acceso, usuarios de servicio y persistencia de datos en disco.

**Objetivo y Aporte:**
* Crear un repositorio centralizado y desacoplado para los backups.
* Simular una arquitectura de nube real (Cloud-Native) en un entorno local.
* Garantizar que si los servidores de aplicaci√≥n son destruidos, los datos de respaldo permanezcan intactos en un "b√∫nker" aislado.

-----

## üìç Fase 4: Configuraci√≥n de Servicios Cr√≠ticos (Las V√≠ctimas)
**Descripci√≥n:**
Puesta en marcha de los servicios que simulan la operaci√≥n del negocio:
1.  **Servidor Web (App Node):** Nginx/Apache sirviendo una aplicaci√≥n de demostraci√≥n.
2.  **Base de Datos (DB Node):** MariaDB configurada para transacciones.
3.  **Acceso P√∫blico:** Configuraci√≥n de *Port Forwarding* para permitir acceso desde dispositivos externos (m√≥viles de la audiencia).

**Objetivo y Aporte:**
* Proveer los activos de informaci√≥n que ser√°n protegidos.
* Demostrar la accesibilidad del servicio para el usuario final antes del "desastre".

-----

## üìç Fase 5: Integridad de Datos y Vol√∫menes L√≥gicos (LVM)
**Descripci√≥n:**
Implementaci√≥n de **LVM (Logical Volume Manager)** en el nodo de Base de Datos. Se migra el almacenamiento de MySQL/MariaDB a un volumen l√≥gico dedicado, permitiendo la gesti√≥n avanzada del disco.

**Objetivo y Aporte:**
* **Atomicidad:** Habilitar la capacidad de tomar *Snapshots* (fotograf√≠as instant√°neas) del disco.
* **Consistencia:** Asegurar que los backups de la base de datos se realicen sin corromper la informaci√≥n, incluso si el sistema est√° recibiendo escrituras en ese milisegundo.

-----

## üìç Fase 6: Configuraci√≥n del Motor de Resiliencia (Restic)
**Descripci√≥n:**
Instalaci√≥n e inicializaci√≥n de **Restic** en los nodos de aplicaci√≥n y base de datos. Se configuran las variables de entorno para conectar con la B√≥veda (MinIO) y se definen las claves de encriptaci√≥n (AES-256).

**Objetivo y Aporte:**
* **Eficiencia:** Implementar la deduplicaci√≥n de datos. Solo se almacenan los bloques que han cambiado, ahorrando espacio y ancho de banda.
* **Seguridad:** Garantizar que ning√∫n dato salga del servidor sin estar cifrado (Encryption at Rest & in Transit).

-----

## üìç Fase 7: Automatizaci√≥n y Planificaci√≥n de Alta Frecuencia
**Descripci√≥n:**
Programaci√≥n de **Systemd Timers** y Servicios (`.service` y `.timer`) para ejecutar los scripts de backup autom√°ticamente. Se define la estrategia de retenci√≥n (GFS) adaptada al evento (retenci√≥n de minutos/horas).

**Objetivo y Aporte:**
* Eliminar el error humano en la ejecuci√≥n de backups.
* Establecer un **RPO (Recovery Point Objective)** cercano a cero, realizando copias de seguridad cada minuto de forma transparente.
* Gestionar el ciclo de vida de los datos (borrado autom√°tico de backups obsoletos).

-----

## üìç Fase 8: Orquestaci√≥n de Recuperaci√≥n (DRP como C√≥digo)
**Descripci√≥n:**
Desarrollo de Playbooks de **Ansible** en el nodo de Control. Estos scripts contienen la l√≥gica para detener servicios, desmontar discos, descargar copias de seguridad desde la B√≥veda y restaurar el sistema a un estado operativo.

**Objetivo y Aporte:**
* **Reducci√≥n del RTO (Recovery Time Objective):** Pasar de horas de restauraci√≥n manual a segundos de restauraci√≥n autom√°tica.
* **Idempotencia:** Asegurar que el proceso de recuperaci√≥n sea repetible y libre de errores bajo presi√≥n.

-----

## üìç Fase 9: Interfaz de Demostraci√≥n y Control Visual
**Descripci√≥n:**
Creaci√≥n de scripts interactivos (Men√∫ de Mando) y monitores de estado en tiempo real. Esto permite al operador ejecutar ataques simulados y restauraciones quir√∫rgicas seleccionando IDs espec√≠ficos de backups.

**Objetivo y Aporte:**
* Hacer visible lo invisible: Permitir que la audiencia "vea" los backups ocurriendo en tiempo real.
* Facilitar la operaci√≥n durante la feria, abstrayendo la complejidad de los comandos de terminal en un men√∫ intuitivo.

-----
