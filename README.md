# üöÄ Proyecto Final SIS313: [T√≠tulo del Proyecto]

> **Asignatura:** SIS313: Infraestructura, Plataformas Tecnol√≥gicas y Redes<br>
> **Semestre:** 2/2025<br>
> **Docente:** Ing. Marcelo Quispe Ortega

## üë• Miembros del Equipo G-11

| Nombre Completo | Rol en el Proyecto | Contacto (GitHub/Email) |
| :--- | :--- | :--- |
| Pomacahua Cardoso Benjamin | Db Node | [Benjamin](https://github.com/BPC-369) |
| Fernando Jose Quispe Gardeazabal | DRP Control  | [FernandoQuispe](https://github.com/FerchoJQG)  |
| Jhoel Mauricio Villca Villca | Boveda  | [JhoelVillca](https://github.com/JhoelVillca) |
| Alan Jesus Uzeda Rivera | APP Node | ----- |

## üéØ I. Objetivo del Proyecto

Describe el objetivo de manera puntual, debe ser espec√≠fica y medible, tal como se define en el banco de proyectos o tal como lo plantean como proyecto.

> **Objetivo:** Dise√±ar e implementar un sistema de Backups Autom√°ticos que utilice una estrategia incremental eficiente, gestione la retenci√≥n y transforme el Plan de Recuperaci√≥n ante Desastres (DRP) en c√≥digo ejecutable para garantizar la integridad transaccional y minimizar el RTO.

## üí° II. Justificaci√≥n e Importancia

Explica por qu√© este proyecto es relevante para una infraestructura universitaria o empresarial. Menciona los problemas de la continuidad operacional (T1) o la seguridad (T5) que resuelve.

> **Justificaci√≥n:** Los m√©todos tradicionales de respaldo (scripts de copia simples) fallan al garantizar la integridad de bases de datos en caliente y dependen de procesos manuales lentos durante una crisis. Este proyecto es vital para la Continuidad Operacional (T1), ya que desacopla el almacenamiento de la infraestructura de c√≥mputo, elimina el error humano mediante la automatizaci√≥n (T6) y asegura la Seguridad (T5) aplicando cifrado en reposo y en tr√°nsito, garantizando que el negocio sobreviva incluso a la destrucci√≥n total de sus servidores principales.

## üõ†Ô∏è III. Tecnolog√≠as y Conceptos Implementados

### 3.1. Tecnolog√≠as Clave

Enumera y describe brevemente el rol de cada software y tecnolog√≠a utilizada.

* **Restic:** Funci√≥n espec√≠fica: Motor de backup con deduplicaci√≥n de datos y cifrado nativo AES-256.
* **MinIO:** Funci√≥n espec√≠fica: Almacenamiento de Objetos (S3 Compatible) que act√∫a como "B√≥veda" inmutable y aislada.
* **LVM (Logical Volume Manager):** Funci√≥n espec√≠fica: Gesti√≥n de snapshots para "congelar" el disco y garantizar consistencia at√≥mica en la BD.
* **Ansible:** Funci√≥n espec√≠fica: Orquestaci√≥n del DRP (Infrastructure as Code) para la restauraci√≥n automatizada de servicios.
* **Tailscale:** Funci√≥n espec√≠fica: Red Overlay (Mesh VPN) para garantizar conectividad segura entre nodos independientemente de la red f√≠sica.
* **Systemd Timers:** Funci√≥n espec√≠fica: Planificaci√≥n de alta frecuencia y gesti√≥n de logs de los servicios de respaldo.

### 3.2. Conceptos de la Asignatura Puestos en Pr√°ctica (T1 - T6)

Marca con un ‚úÖ los temas avanzados de la asignatura que fueron implementados:

* **Alta Disponibilidad (T2) y Tolerancia a Fallos:** ‚úÖ Desacoplamiento del almacenamiento (MinIO) para supervivencia de datos ante desastres en nodos de aplicaci√≥n.
* **Seguridad y Hardening (T5):** ‚úÖ Implementaci√≥n de "Encryption at Rest" (Restic), t√∫neles cifrados (Tailscale) y Hardening SSH mediante llaves Ed25519.
* **Automatizaci√≥n y Gesti√≥n (T6):** ‚úÖ Implementaci√≥n de DRP como C√≥digo (Ansible Playbooks) y automatizaci√≥n de backups con Systemd.
* **Balanceo de Carga/Proxy (T3/T4):**  *(No aplica en esta arquitectura enfocada en DRP)*
* **Monitoreo (T4/T1):** ‚úÖ Implementaci√≥n de Dashboard en tiempo real (`monitor.sh`) para observabilidad de la creaci√≥n de snapshots.
* **Networking Avanzado (T3):** ‚úÖ Implementaci√≥n de Red Overlay para abstracci√≥n de infraestructura f√≠sica y Port Forwarding (NAT) para acceso p√∫blico.


## üåê IV. Dise√±o de la Infraestructura y Topolog√≠a

### 4.1. Dise√±o Esquem√°tico

Incluye un diagrama de la topolog√≠a final. Muestra claramente la segmentaci√≥n de red, las IPs utilizadas, y los flujos de tr√°fico.

> 
| VM/Host | Rol | IP Overlay (Tailscale) | Red L√≥gica | SO |
| :--- | :--- | :--- | :--- | :--- |
| **VM1 (minio-vault)** | B√≥veda de Almacenamiento (S3) | 100.x.y.z | Red Mesh | Ubuntu 22.04 |
| **VM2 (app-node)** | Servidor Web (V√≠ctima 1) | 100.x.y.z | Red Mesh | Ubuntu 22.04 |
| **VM3 (db-node)** | Base de Datos + LVM (V√≠ctima 2) | 100.x.y.z | Red Mesh | Ubuntu 22.04 |
| **VM4 (drp-control)**| Cerebro / Control Ansible | 100.x.y.z | Red Mesh | Ubuntu 22.04 |


### 4.2. Estrategia Adoptada (Opcional)

Describe la estrategia de dise√±o y las decisiones cr√≠ticas.

* **Estrategia "Snapshot-First" (Integridad):** Se prioriz√≥ la consistencia de datos sobre la velocidad de copia pura. Antes de cada backup de BD, se utiliza LVM para crear una "instant√°nea" del sistema de archivos, garantizando que no se copien transacciones a medias.
* **Estrategia de Recuperaci√≥n Quir√∫rgica:** Se implement√≥ un men√∫ interactivo ("Time Travel") que permite seleccionar versiones espec√≠ficas de los backups en lugar de restaurar ciegamente la √∫ltima versi√≥n, protegiendo contra errores l√≥gicos recientes.
## üìã V. Gu√≠a de Implementaci√≥n y Puesta en Marcha

Documenta los pasos esenciales para que cualquier persona pueda replicar el proyecto (instalaci√≥n, configuraci√≥n de ficheros clave, comandos).

### 5.1. Pre-requisitos
  * 4 M√°quinas Virtuales (o f√≠sicas) con Ubuntu Server 22.04/24.04.
  * Acceso root/sudo y conectividad a Internet para instalaci√≥n de paquetes.
  * Discos secundarios virtuales configurados en VM1 (20GB) y VM3 (10GB).
### 5.2. Despliegue (Ejecuci√≥n de la Automatizaci√≥n)
1.  **Red:** Instalar Tailscale en todos los nodos y configurar `/etc/hosts` como redundancia DNS.
2.  **Almacenamiento:** Formatear discos secundarios, montar `/mnt/data` y desplegar contenedor MinIO en VM1.
3.  **Servicios:** Desplegar LAMP Stack en VM2/VM3 y configurar LVM en VM3 (`vg_datos/lv_mysql`).
4.  **Resiliencia:** Inicializar repositorios Restic en VM2/VM3 apuntando a VM1 y activar Systemd Timers.
5.  **Control:** Configurar inventario de Ansible en VM4, intercambiar llaves SSH y desplegar scripts de men√∫.

### 5.3. Ficheros de Configuraci√≥n Clave
  * `/usr/local/bin/backup_db.sh`: Script cr√≠tico que orquesta el congelamiento LVM y la ejecuci√≥n de Restic.
  * `/home/admin-drp/ansible-drp/restore_db.yml`: Playbook de Ansible para la restauraci√≥n automatizada, limpieza y trasplante de datos.
  * `/home/admin-drp/demo/menu.sh`: Interfaz de Centro de Mando para gesti√≥n de crisis y selecci√≥n de snapshots.
  * `/etc/systemd/system/backup-db.timer`: Planificador de alta frecuencia (minuto a minuto).

**Incluir adem√°s los archivos de configuraci√≥n y software a utilizar dentro del proyecto y organizados en carpetas.**

## ‚ö†Ô∏è VI. Pruebas y Validaci√≥n

| Prueba Realizada | Resultado Esperado | Resultado Obtenido |
| :--- | :--- | :--- |
| **Simulaci√≥n de Ataque Web** (Borrado de `index.php`) | El sitio debe devolver Error 404 y recuperarse autom√°ticamente tras ejecutar Ansible. | **[√âXITO]** Recuperado en \< 10s. |
| **Destrucci√≥n de Base de Datos** (`rm -rf /var/lib/mysql`) | El servicio MariaDB debe fallar. Tras la restauraci√≥n, los datos transaccionales deben reaparecer intactos. | **[√âXITO]** Datos √≠ntegros verificados. |
| **Integridad de Snapshot LVM** | El backup no debe bloquear la base de datos ni corromper archivos abiertos durante la escritura. | **[√âXITO]** Backup realizado en caliente sin errores. |


## üìö VII. Conclusiones y Lecciones Aprendidas

Se logr√≥ implementar una arquitectura resiliente capaz de recuperar servicios cr√≠ticos en segundos, cumpliendo el objetivo de automatizaci√≥n (T6) y continuidad (T1).
Es importante no solo enfocarse en evitar que una web se caiga, si no este proyecto nos ilumino haciendo darnos cuenta que tambien hay que pensar en que pasa si la web se cae.
